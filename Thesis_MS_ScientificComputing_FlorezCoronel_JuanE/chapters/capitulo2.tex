\chapter{Literature Review}  

\section{Introduction to \texorpdfstring{\gls{fmri}}{fMRI}}

\gls{mri} is a powerful medical imaging technique that has revolutionized the 
field of diagnostic medicine \cite{westbrook2018mri}. At its core, \gls{mri} 
relies on the interaction of protons within the human body with strong magnetic 
fields and radiofrequency pulses \cite{hashemi2012mri}. These magnetic fields, 
often generated by superconducting magnets, align the protons within the body's 
tissues \cite{berger2002does}. Subsequent radiofrequency pulses perturb this 
alignment, causing the protons to emit radiofrequency signals as they return 
to their original alignment. By detecting these signals and their variations, 
\gls{mri} scanners create high-resolution anatomical images that provide 
detailed insights into the body's internal structures \cite{guven2023brain}. 
This non-invasive and versatile imaging modality has become indispensable in 
clinical diagnosis, research, and medical practice, offering a wealth of 
information for assessing various medical conditions.

As traditional \gls{mri} focuses mainly on the generation of static anatomic 
images of the internal structures of the body \cite{westbrook2018mri}, 
\gls{fmri} brings a new advantage as it captures the dynamic activities of 
the body part studied 
\cite{buchbinder2016functional, christopher2008applications, logothetis2008we}. 
The critical difference is that magnetic resonance is based mainly on the 
interaction of protons with magnetic fields to produce detailed anatomic 
images in the data acquisition process. At the same time, the \gls{fmri} 
takes advantage of the \gls{bold} contrast to indirectly measure neural activity 
by detecting changes in the oxygenation level of the blood 
\cite{smith2004overview}. This fundamental change of emphasis allows \gls{fmri} 
to study the visualization and mapping of brain regions activated during 
specific cognitive tasks, making it a very used tool in cognitive neuroscience 
and neuropsychology \cite{orchard2003simultaneous, ruschemeyer2006native}. 

In the domain of \gls{fmri}, \gls{bold} contrast is within the most important 
concepts to be studied \cite{logothetis2004nature}. The essence of \gls{bold} 
contrast relies on the observation that neural activity generates changes in 
local blood oxygenation levels \cite{lindquist2008rapid}. As brain regions 
become more active, they demand increased oxygen and glucose to sustain their 
functions \cite{lindquist2008statistical}. In response, blood flow to these 
regions is expected to be altered to meet the demand. Importantly, hemoglobin, 
the oxygen-carrying molecule in blood, behaves differently when oxygenated 
and deoxygenated, affecting its magnetic properties 
\cite{uyuklu2009effect, pauling1936magnetic, bren2015discovery}. When 
oxygenation levels of the blood change, it generates fluctuations in its 
magnetic properties; this process is all captured by \gls{fmri} experiments
 \cite{buxton2012dynamic}.

As expected, this long data reading process generates a significant amount 
of noise because of all the factors that are expected to work correctly during 
the measurements. In addition to that, it is known that high-level cognitive 
tasks produce low-signal scenarios in \gls{fmri} experiments 
\cite{cui2011quantitative}. To quantify the amount of noise concerning the 
signal studied, researchers use metrics such as the \gls{snr} and the
 \gls{cnr} \cite{welvaert2013definition}. The \gls{snr} quantifies the ratio 
 of the strength of the signal arising from brain activity to the background 
 noise inherent in the imaging process. Higher \gls{snr} values indicate a 
 more robust and detectable signal. Similarly, \gls{cnr} assesses the contrast 
 between activated and non-activated brain regions by comparing the difference 
 in signal intensity between them to the noise level. A higher \gls{cnr} 
 signifies a stronger and more discernible activation signal relative to 
 background noise.

\section{Analysis of \texorpdfstring{\gls{fmri}}{fMRI} Data - Time Series, 
Activation Detection and Final Image}

Voxels, short for volumetric pixels, are fundamental building blocks in 
\gls{fmri} analysis \cite{norman2006beyond}. They represent \gls{3d} units 
within the image and play a crucial role in discretizing the space studied. 
Each voxel corresponds to a tiny, well-defined volume in the brain, and within 
this volume, \gls{fmri} data, particularly \gls{bold} signal measurements, 
are collected over time \cite{li2009voxel}. These measurements over time can 
be compiled into a time series and, more specifically, with a linear relation. 
The general linear model for time series analysis is a fundamental technique 
in \gls{fmri} 
data processing because it captures temporal dynamics of neural activity
 \cite{kiebel2007general, friston1994statistical}.

Detection of neural activity in the \gls{roi} is a crucial field of study 
in \gls{fmri} research as it enables scientists to identify brain regions 
that exhibit significant changes in activity in response to specific stimuli 
or tasks \cite{ardekani1999activation}. The identification of the \gls{roi} 
in \gls{fmri} is called image masking \cite{peer2016intensity}. The \gls{roi} 
can correspond to anatomically defined brain structures, functionally 
significant areas, or areas of interest for a particular study 
\cite{poldrack2007region}. Image masking is employed to improve the precision 
and efficiency of analyses, as it allows researchers to isolate and concentrate 
on the neural activity occurring within predefined brain regions 
\cite{mitsis2008regions}. By delineating the \gls{roi}, image masking effectively 
filters out irrelevant data, reducing noise and enhancing the sensitivity of 
statistical analyses. One method to apply the image masking, as implemented in 
NiLearn \cite{abraham2014machine}, is based on a heuristic proposed by T.Nichols 
\cite{luo2003diagnosis}: find the least dense point of the histogram, between a 
lower cutoff and an upper cutoff of the total image histogram.

Within the area of neural activity, some researchers use frequentist approaches 
to detect activation in \gls{fmri} studies. These approaches can be described 
as statistical methods that adopt a null hypothesis tested using p-values to 
determine whether a brain region is significantly activated by a particular 
stimulus or condition \cite{friston2002classical, almodovar2019fast}. These 
methods are widely used in \gls{fmri} research 
\cite{almodovar2019fast, josephs1997event, worsley1995analysis, worsley1996searching}. 
Still, they have been criticized for their limitations, such as their problems 
addressing hemodynamic variability and the spatio-temporal autocorrelations in 
\gls{fmri} \cite{woolrich2012years}.

An essential tool to be discussed that is relevant in generating low-noise 
activation maps is image smoothing \cite{lee1983digital}. Image smoothing is a 
crucial step in activation map analysis because it helps to reduce noise and 
improve the localization of activated brain regions 
\cite{lindquist2010adaptive, strappini2017adaptive, garg2016quality}. By 
smoothing the probability maps, researchers can more easily identify the 
brain regions most strongly activated by a particular stimulus or condition
 \cite{tabelow2006analyzing}. Adaptive smoothing has been a common technique
  in activation detection in \gls{fmri}, and researchers have always complimented
   this technique with frequentist approaches 
   \cite{triantafyllou2006effect, mikl2008effects, liu2017functional}. These 
   methods yield precise results. However, there is a gap in the literature 
   regarding using adaptive smoothing with Bayesian approaches.

After obtaining the final activation map, researchers must be able to compare 
methods and test their findings' reliability. Hence, tools like the \gls{ji} 
were introduced to the area of \gls{fmri}. The \gls{ji} was initially introduced 
by Paul Jaccard in 1901 \cite{jaccard1901etude}; later, researchers found 
application in \gls{fmri} analysis, as discussed in \cite{maitra2010re}. 
The \gls{ji} measures the similarity between two sets by calculating the 
intersection over the union of their elements. In \gls{fmri}, it assesses 
the overlap and consistency of brain activation patterns across different 
subjects, conditions, or studies. A higher \gls{ji} indicates a more 
remarkable similarity between activation maps.

\section{Bayesian Analysis}

Bayesian analysis is essential in data analysis and statistical reasoning 
\cite{bernardo1994bayesian, bolstad2016introduction}. It is a probabilistic 
framework that quantifies uncertainty and makes inferences from data 
\cite{van2021bayesian}. Unlike traditional frequentist statistics, which 
treat model parameters as fixed and unknown values, Bayesians treat these 
parameters as random variables, encapsulating our uncertainty about their 
values with probability distributions \cite{bayarri2004interplay}. In the 
Bayesian analysis, prior beliefs about parameters are combined with observed 
data through Bayes' Rule to construct the posterior distribution. The prior 
distribution is the key in Bayesian approaches as it represents the previous 
knowledge or assumptions about the random variables in question 
\cite{gelman2002prior, stone2013bayes}.

The selection of a prior distribution is relevant in Bayesian modeling, as 
it profoundly influences the posterior distribution \cite{kass1996formal}. 
When choosing a prior distribution, researchers must balance incorporating 
relevant domain expertise and ensuring that the prior does not dominate the 
outcome of the posterior. This requires careful consideration of the prior's 
shape, scale, and informativeness \cite{perez2002expected}. Various methods, 
such as non-informative or weakly informative priors, hierarchical modeling, 
and empirical Bayes techniques, offer strategies for selecting appropriate 
priors based on the available information and the specific context of the 
analysis \cite{terenin2017noninformative}. A good choice of prior distributions 
incorporates valuable previous knowledge while preserving the capacity of data 
to update and refine the result, thus yielding more robust and insightful 
posterior distributions \cite{gelman2013bayesian}.

\section{Relevant Distributions}

Given the nature of random variables that represent probability values, 
distributions whose range lies between 0 and 1 are studied. The \gls{tn} is 
a relevant probability distribution with applications in modeling extreme 
values that fall within a specific range \cite{burkardt2014truncated}. This 
distribution is characterized by the constraint that its values lie within a 
defined interval, effectively truncating the tails of the standard normal 
distribution.

In \cite{david2004order}, the concept of the domain of maximal attraction is 
presented as a fundamental idea of the extreme value theory. The domain of maximal attraction
 characterizes the asymptotic 
behavior of extreme value distributions as it represents a specific class of 
distributions that exhibit remarkable convergence properties when dealing with 
extreme values. It is the set of distributions for which the maxima of independent 
and identically distributed random variables converge to one of the three extreme 
value distributions: the Gumbel, Fr√©chet, or Weibull distribution, depending on 
the characteristics of the underlying distribution \cite{gorgoso2014use}.